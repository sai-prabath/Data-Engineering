{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMdJOeYMEk6xRig6Sqo59Hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2RkwLW5jmVlo","executionInfo":{"status":"ok","timestamp":1725345817915,"user_tz":-330,"elapsed":37238,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"eaa9fce1-aa14-4cdd-8817-dc6e87f4cf45"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# https://codeshare.io/pAe0RV\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["! pip install pyspark"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fDokf4T2oW2l","executionInfo":{"status":"ok","timestamp":1725345983007,"user_tz":-330,"elapsed":45860,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"09258b15-452e-44cc-d245-5c6b2460bdae"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyspark\n","  Downloading pyspark-3.5.2.tar.gz (317.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n","Building wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.5.2-py2.py3-none-any.whl size=317812365 sha256=b3f121c3595d4f009275ab679fe29198a4f0e64c58d94b6e83614d570a24701e\n","  Stored in directory: /root/.cache/pip/wheels/34/34/bd/03944534c44b677cd5859f248090daa9fb27b3c8f8e5f49574\n","Successfully built pyspark\n","Installing collected packages: pyspark\n","Successfully installed pyspark-3.5.2\n"]}]},{"cell_type":"code","source":["# step 1\n","import pandas as pd\n","from datetime import datetime\n","\n","data = {\n","    \"TransactionID\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n","    \"CustomerID\": [101, 102, 103, 101, 104, 102, 103, 104, 101, 105],\n","    \"ProductID\": [501, 502, 501, 503, 504, 502, 503, 504, 501, 505],\n","    \"Quantity\": [2, 1, 4, 3, 1, 2, 5, 1, 2, 1],\n","    \"Price\": [150.0, 250.0, 150.0, 300.0, 450.0, 250.0, 300.0, 450.0, 150.0, 550.0],\n","    \"Date\": [\n","        datetime(2024, 9, 1),\n","        datetime(2024, 9, 1),\n","        datetime(2024, 9, 2),\n","        datetime(2024, 9, 2),\n","        datetime(2024, 9, 3),\n","        datetime(2024, 9, 3),\n","        datetime(2024, 9, 4),\n","        datetime(2024, 9, 4),\n","        datetime(2024, 9, 5),\n","        datetime(2024, 9, 5)\n","    ]\n","}\n","\n","# DataFrame\n","df = pd.DataFrame(data)\n","\n","# Save the DataFrame to a CSV file\n","df.to_csv('/content/drive/MyDrive/DataEngineering/sales_data.csv', index=False)\n","\n","print(\"Sample sales dataset has been created and saved as 'sales_data.csv'.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o7xDXI0xnZb_","executionInfo":{"status":"ok","timestamp":1725345988089,"user_tz":-330,"elapsed":1480,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"957a5576-0268-4202-c91a-829c17b9333d"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample sales dataset has been created and saved as 'sales_data.csv'.\n"]}]},{"cell_type":"code","source":["# step 2\n","\n","from pyspark.sql import SparkSession\n","\n","spark = SparkSession.builder.appName(\"Sales Dataset Analysis\").getOrCreate()\n","\n","sales_df = spark.read.csv(\"/content/drive/MyDrive/DataEngineering/sales_data.csv\", header=True, inferSchema=True)\n","\n","sales_df.show(4) #verify"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S1rVhb54oKaX","executionInfo":{"status":"ok","timestamp":1725346651429,"user_tz":-330,"elapsed":1387,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"7d19de7c-3542-4875-b1ed-2a739c099841"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------------+----------+---------+--------+-----+----------+\n","|TransactionID|CustomerID|ProductID|Quantity|Price|      Date|\n","+-------------+----------+---------+--------+-----+----------+\n","|            1|       101|      501|       2|150.0|2024-09-01|\n","|            2|       102|      502|       1|250.0|2024-09-01|\n","|            3|       103|      501|       4|150.0|2024-09-02|\n","|            4|       101|      503|       3|300.0|2024-09-02|\n","+-------------+----------+---------+--------+-----+----------+\n","only showing top 4 rows\n","\n"]}]},{"cell_type":"code","source":["# step 3\n","\n","# printing schema\n","sales_df.printSchema()\n","\n","# first 5 rows\n","sales_df.show(5)\n","\n","# summary statistics for numeric columns\n","sales_df.describe([\"Quantity\", \"Price\"]).show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pAi5eFb8paHO","executionInfo":{"status":"ok","timestamp":1725346348608,"user_tz":-330,"elapsed":2902,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"2508b6d7-32c7-4ecb-9db8-dc08ca7f7f8a"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- TransactionID: integer (nullable = true)\n"," |-- CustomerID: integer (nullable = true)\n"," |-- ProductID: integer (nullable = true)\n"," |-- Quantity: integer (nullable = true)\n"," |-- Price: double (nullable = true)\n"," |-- Date: date (nullable = true)\n","\n","+-------------+----------+---------+--------+-----+----------+\n","|TransactionID|CustomerID|ProductID|Quantity|Price|      Date|\n","+-------------+----------+---------+--------+-----+----------+\n","|            1|       101|      501|       2|150.0|2024-09-01|\n","|            2|       102|      502|       1|250.0|2024-09-01|\n","|            3|       103|      501|       4|150.0|2024-09-02|\n","|            4|       101|      503|       3|300.0|2024-09-02|\n","|            5|       104|      504|       1|450.0|2024-09-03|\n","+-------------+----------+---------+--------+-----+----------+\n","only showing top 5 rows\n","\n","+-------+-----------------+-----------------+\n","|summary|         Quantity|            Price|\n","+-------+-----------------+-----------------+\n","|  count|               10|               10|\n","|   mean|              2.2|            300.0|\n","| stddev|1.398411797560202|141.4213562373095|\n","|    min|                1|            150.0|\n","|    max|                5|            550.0|\n","+-------+-----------------+-----------------+\n","\n"]}]},{"cell_type":"code","source":["# step 4\n","\n","# 1.Calculate the Total Sales Value for Each Transaction\n","sales_df = sales_df.withColumn(\"TotalSales\", sales_df[\"Quantity\"] * sales_df[\"Price\"])\n","sales_df.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xcbFzAU8qLGV","executionInfo":{"status":"ok","timestamp":1725347210592,"user_tz":-330,"elapsed":613,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"a5bf5b03-6fd8-454f-e2bf-7ca3637e32d3"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------------+----------+---------+--------+-----+----------+----------+\n","|TransactionID|CustomerID|ProductID|Quantity|Price|      Date|TotalSales|\n","+-------------+----------+---------+--------+-----+----------+----------+\n","|            1|       101|      501|       2|150.0|2024-09-01|     300.0|\n","|            2|       102|      502|       1|250.0|2024-09-01|     250.0|\n","|            3|       103|      501|       4|150.0|2024-09-02|     600.0|\n","|            4|       101|      503|       3|300.0|2024-09-02|     900.0|\n","|            5|       104|      504|       1|450.0|2024-09-03|     450.0|\n","|            6|       102|      502|       2|250.0|2024-09-03|     500.0|\n","|            7|       103|      503|       5|300.0|2024-09-04|    1500.0|\n","|            8|       104|      504|       1|450.0|2024-09-04|     450.0|\n","|            9|       101|      501|       2|150.0|2024-09-05|     300.0|\n","|           10|       105|      505|       1|550.0|2024-09-05|     550.0|\n","+-------------+----------+---------+--------+-----+----------+----------+\n","\n"]}]},{"cell_type":"code","source":["# 2.Group By ProductID and Calculate Total Sales Per Product\n","total_sales_by_product = sales_df.groupBy(\"ProductID\").sum(\"TotalSales\").withColumnRenamed(\"sum(TotalSales)\",\"TotalSales\")\\\n","                        .orderBy(\"sum(TotalSales)\", ascending=False)\n","total_sales_by_product.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0WzkvzqwsDXk","executionInfo":{"status":"ok","timestamp":1725347224783,"user_tz":-330,"elapsed":617,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"55bd7fb4-aaef-444a-e0e0-75f657888785"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+----------+\n","|ProductID|TotalSales|\n","+---------+----------+\n","|      503|    2400.0|\n","|      501|    1200.0|\n","|      504|     900.0|\n","|      502|     750.0|\n","|      505|     550.0|\n","+---------+----------+\n","\n"]}]},{"cell_type":"code","source":["# 3.Identify the Top-Selling Product\n","top_selling_product = total_sales_by_product.limit(1)\n","top_selling_product.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fDvmcj8YsmI0","executionInfo":{"status":"ok","timestamp":1725347230534,"user_tz":-330,"elapsed":1226,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"d7692909-c8e4-4e12-df71-d9fc3e80c14a"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+----------+\n","|ProductID|TotalSales|\n","+---------+----------+\n","|      503|    2400.0|\n","+---------+----------+\n","\n"]}]},{"cell_type":"code","source":["# 4.Calculate the Total Sales by Date\n","total_sales_by_date = sales_df.groupBy(\"Date\").sum('TotalSales').orderBy(\"Date\")\n","total_sales_by_date.show()\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"52cgjbEGtgcW","executionInfo":{"status":"ok","timestamp":1725347329655,"user_tz":-330,"elapsed":1189,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"26223dd8-af1e-4f41-ce42-6ef9db8fa333"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+---------------+\n","|      Date|sum(TotalSales)|\n","+----------+---------------+\n","|2024-09-01|          550.0|\n","|2024-09-02|         1500.0|\n","|2024-09-03|          950.0|\n","|2024-09-04|         1950.0|\n","|2024-09-05|          850.0|\n","+----------+---------------+\n","\n"]}]},{"cell_type":"code","source":["# 5.Filter High-Value Transactions\n","high_value_transactions = sales_df.filter(sales_df[\"TotalSales\"] > 500)\n","high_value_transactions.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5P6VQ80rtlYz","executionInfo":{"status":"ok","timestamp":1725347366391,"user_tz":-330,"elapsed":600,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"07f320bf-fe8f-43ee-a59d-836a586eca77"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------------+----------+---------+--------+-----+----------+----------+\n","|TransactionID|CustomerID|ProductID|Quantity|Price|      Date|TotalSales|\n","+-------------+----------+---------+--------+-----+----------+----------+\n","|            3|       103|      501|       4|150.0|2024-09-02|     600.0|\n","|            4|       101|      503|       3|300.0|2024-09-02|     900.0|\n","|            7|       103|      503|       5|300.0|2024-09-04|    1500.0|\n","|           10|       105|      505|       1|550.0|2024-09-05|     550.0|\n","+-------------+----------+---------+--------+-----+----------+----------+\n","\n"]}]},{"cell_type":"code","source":["# 6.Identify Repeat Customers\n","repeat_customers = sales_df.groupBy(\"CustomerID\").count().filter(\"count > 1\").orderBy(\"count\", ascending=False)\n","repeat_customers.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mDRSWxHGuFZM","executionInfo":{"status":"ok","timestamp":1725347452588,"user_tz":-330,"elapsed":1258,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"e23c1fe1-b462-4dda-de6a-9fb3adf80b23"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+-----+\n","|CustomerID|count|\n","+----------+-----+\n","|       101|    3|\n","|       103|    2|\n","|       102|    2|\n","|       104|    2|\n","+----------+-----+\n","\n"]}]},{"cell_type":"code","source":["# 7.Calculate the Average Sale Price Per Product\n","average_sale_price = sales_df.groupBy(\"ProductID\").avg('Price').withColumnRenamed(\"avg(Price)\",\"AveragePrice\").orderBy(\"AveragePrice\", ascending=False)\n","average_sale_price.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e_Ncn4bUuUEb","executionInfo":{"status":"ok","timestamp":1725347600744,"user_tz":-330,"elapsed":583,"user":{"displayName":"sai prabath","userId":"06763418138744745121"}},"outputId":"2e86cd79-c6a7-4cf3-e22b-d4e3ec2f67b4"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+------------+\n","|ProductID|AveragePrice|\n","+---------+------------+\n","|      505|       550.0|\n","|      504|       450.0|\n","|      503|       300.0|\n","|      502|       250.0|\n","|      501|       150.0|\n","+---------+------------+\n","\n"]}]},{"cell_type":"markdown","source":["# Exercise: Analyzing a Sample Sales Dataset Using PySpark\n","\n","In this exercise, you'll work with a simulated sales dataset and perform various data transformations and analyses using PySpark. The dataset includes fields like `TransactionID`, `CustomerID`, `ProductID`, `Quantity`, `Price`, and `Date`. Your task is to generate the dataset, load it into PySpark, and answer specific questions by performing data operations.\n","\n","---\n","\n","### **Part 1: Dataset Preparation**\n","\n","#### **Step 1: Generate the Sample Sales Dataset**\n","\n","Before starting the analysis, you'll need to create the sample sales dataset. Use the following Python code to generate the dataset and save it as a CSV file.\n","\n","1. **Run the Dataset Preparation Script:**\n","\n","   ```python\n","   import pandas as pd\n","   from datetime import datetime\n","\n","   # Sample sales data\n","   data = {\n","       \"TransactionID\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n","       \"CustomerID\": [101, 102, 103, 101, 104, 102, 103, 104, 101, 105],\n","       \"ProductID\": [501, 502, 501, 503, 504, 502, 503, 504, 501, 505],\n","       \"Quantity\": [2, 1, 4, 3, 1, 2, 5, 1, 2, 1],\n","       \"Price\": [150.0, 250.0, 150.0, 300.0, 450.0, 250.0, 300.0, 450.0, 150.0, 550.0],\n","       \"Date\": [\n","           datetime(2024, 9, 1),\n","           datetime(2024, 9, 1),\n","           datetime(2024, 9, 2),\n","           datetime(2024, 9, 2),\n","           datetime(2024, 9, 3),\n","           datetime(2024, 9, 3),\n","           datetime(2024, 9, 4),\n","           datetime(2024, 9, 4),\n","           datetime(2024, 9, 5),\n","           datetime(2024, 9, 5)\n","       ]\n","   }\n","\n","   # Create a DataFrame\n","   df = pd.DataFrame(data)\n","\n","   # Save the DataFrame to a CSV file\n","   df.to_csv('sales_data.csv', index=False)\n","\n","   print(\"Sample sales dataset has been created and saved as 'sales_data.csv'.\")\n","   ```\n","\n","2. **Verify the Dataset:**\n","   - After running the script, ensure that the file `sales_data.csv` has been created in your working directory.\n","\n","---\n","\n","### **Part 2: Load and Analyze the Dataset Using PySpark**\n","\n","Now that you have the dataset, your task is to load it into PySpark and perform the following analysis tasks.\n","\n","#### **Step 2: Load the Dataset into PySpark**\n","\n","1. **Initialize the SparkSession:**\n","   - Create a Spark session named `\"Sales Dataset Analysis\"`.\n","\n","2. **Load the CSV File into a PySpark DataFrame:**\n","   - Load the `sales_data.csv` file into a PySpark DataFrame.\n","   - Display the first few rows of the DataFrame to verify that the data is loaded correctly.\n","\n","#### **Step 3: Explore the Data**\n","\n","Explore the data to understand its structure.\n","\n","1. **Print the Schema:**\n","   - Display the schema of the DataFrame to understand the data types.\n","\n","2. **Show the First Few Rows:**\n","   - Display the first 5 rows of the DataFrame.\n","\n","3. **Get Summary Statistics:**\n","   - Get summary statistics for numeric columns (`Quantity` and `Price`).\n","\n","#### **Step 4: Perform Data Transformations and Analysis**\n","\n","Perform the following tasks to analyze the data:\n","\n","1. **Calculate the Total Sales Value for Each Transaction:**\n","   - Add a new column called `TotalSales`, calculated by multiplying `Quantity` by `Price`.\n","\n","2. **Group By ProductID and Calculate Total Sales Per Product:**\n","   - Group the data by `ProductID` and calculate the total sales for each product.\n","\n","3. **Identify the Top-Selling Product:**\n","   - Find the product that generated the highest total sales.\n","\n","4. **Calculate the Total Sales by Date:**\n","   - Group the data by `Date` and calculate the total sales for each day.\n","\n","5. **Filter High-Value Transactions:**\n","   - Filter the transactions to show only those where the total sales value is greater than ₹500.\n","\n","---\n","\n","### **Additional Challenge (Optional):**\n","\n","If you complete the tasks above, try extending your analysis with the following challenges:\n","\n","1. **Identify Repeat Customers:**\n","   - Count how many times each customer has made a purchase and display the customers who have made more than one purchase.\n","\n","2. **Calculate the Average Sale Price Per Product:**\n","   - Calculate the average price per unit for each product and display the results."],"metadata":{"id":"gQaYnFQ6mzn-"}},{"cell_type":"code","source":[],"metadata":{"id":"1Ui4zlR0msaV"},"execution_count":null,"outputs":[]}]}