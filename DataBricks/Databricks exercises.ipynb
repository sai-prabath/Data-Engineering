{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8763fd8-0de0-4964-be47-69fcbc45ead7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 50, Average: 12.5\n"
     ]
    }
   ],
   "source": [
    "#Task:1. Creating a Databricks Notebook and perform basic operation \n",
    "numbers = [5, 10, 15, 20]\n",
    "total = sum(numbers)\n",
    "average = total / len(numbers)\n",
    "print(f\"Total: {total}, Average: {average}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7354b121-b99e-45b1-9ba4-a7628c510653",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster is successfully configured!!!\n"
     ]
    }
   ],
   "source": [
    "# Task: 2. Setting Up Azure Databricks Workspace and Configuring Clusters\n",
    "print(\"Cluster is successfully configured!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4348a6cb-f704-4a7e-993e-bd92b3cedc88",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbutils.fs.cp(\"file:/Workspace/Shared/real_time_streaming_data.csv\",\"dbfs:/FileStore/real_time_streaming_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "170c7f1c-d67f-4293-a5da-c7d1a5373a55",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbutils.fs.cp(\"file:/Workspace/Shared/exe_sales_data.csv\",\"dbfs:/FileStore/exe_sales_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0045bc9d-2dfc-4962-a7cb-23e76537f502",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbutils.fs.cp(\"file:/Workspace/Shared/exe_transaction_data.csv\",\"dbfs:/FileStore/exe_transaction_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4e16b05-1f10-4824-abee-1755f29caa5c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Task : 3. Real-time data processing with databricks and Real-time aggregation\n",
    "schema=\"event_time TIMESTAMP, event_type STRING, user_id STRING, amount DOUBLE\"\n",
    "streamind_data=spark.readStream.format(\"csv\").schema(schema).option(\"header\",\"true\").load(\"dbfs:/FileStore/\")\n",
    "aggregated_data=(streamind_data.groupBy(\"event_type\").agg({\"amount\":\"sum\"}).withColumnRenamed(\"sum(amount)\",\"total_amount\"))\n",
    "query = (aggregated_data.writeStream\n",
    "         .outputMode(\"complete\")\n",
    "         .format(\"console\")\n",
    "         .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0ba5d5e-0832-4247-8061-a3cab3381630",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Task: 4 Data Exploration and Visualization in Databricks and perform EDA\n",
    "from pyspark.sql.functions import col\n",
    "df = spark.read.csv(\"dbfs:/FileStore/exe_sales_data.csv\", header=True, inferSchema=True)\n",
    "df.groupBy(\"category\").sum(\"amount\").display()\n",
    "df.select(\"amount\", \"quantity\").display()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "87c85cbb-2c7d-4322-86fe-5a76aea9fce6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert the total sales per product to Pandas\n",
    "df_pandas_category = df.groupBy(\"Product\").agg({\"Price\": \"sum\"}).toPandas()\n",
    "\n",
    "# Plot using Matplotlib\n",
    "df_pandas_category.plot(kind='bar', x='Product', y='sum(Price)', legend=False)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title(\"Total Sales by Product\")\n",
    "plt.xlabel(\"Product\")\n",
    "plt.ylabel(\"Total Sales (Price)\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "92df4629-489e-4a3c-90a2-c9bfe68beb24",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert the necessary columns to Pandas\n",
    "df_pandas_scatter = df.select(\"Quantity\", \"Price\").toPandas()\n",
    "\n",
    "# Plot using Matplotlib\n",
    "plt.scatter(df_pandas_scatter['Quantity'], df_pandas_scatter['Price'], alpha=0.5)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title(\"Quantity vs Price\")\n",
    "plt.xlabel(\"Quantity\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ef2d133-0bf0-4608-bf49-f3fedef81d98",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert the total sales per product to Pandas\n",
    "df_pandas_customer = df.groupBy(\"Product\").agg({\"Price\": \"sum\"}).toPandas()\n",
    "\n",
    "# Plot using Matplotlib\n",
    "df_pandas_customer.plot(kind='bar', x='Product', y='sum(Price)', legend=False)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title(\"Total Sales by Product\")\n",
    "plt.xlabel(\"Product\")\n",
    "plt.ylabel(\"Total Sales (Price)\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "df6c5043-8fb8-48c3-914c-fbd0c07ec7b7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Group by product, sum the quantity and price, and convert to Pandas\n",
    "df_pandas_quantity_vs_sales = df.groupBy(\"Product\") \\\n",
    "    .agg({\"Quantity\": \"sum\", \"Price\": \"sum\"}).toPandas()\n",
    "\n",
    "# Plot using Matplotlib\n",
    "plt.scatter(df_pandas_quantity_vs_sales['sum(Quantity)'], df_pandas_quantity_vs_sales['sum(Price)'])\n",
    "\n",
    "# Customize the plot\n",
    "plt.title(\"Total Quantity vs Total Sales by Product\")\n",
    "plt.xlabel(\"Total Quantity\")\n",
    "plt.ylabel(\"Total Sales (Price)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0779380d-ba98-4121-a402-5c354cff757b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Task:5. Reading and Writing Data in Databricks in different formats \n",
    "df_csv = spark.read.csv(\"dbfs:/FileStore/exe_sales_data.csv\", header=True, inferSchema=True)\n",
    "df_csv.write.format(\"delta\").mode(\"overwrite\").save(\"dbfs:/FileStore/delta_table\")\n",
    "print(\"Writing to the delta table completed\")\n",
    "df_csv.write.mode(\"overwrite\").parquet(\"dbfs:/FileStore/parquet_table\")\n",
    "print(\"Writing to the parquet file completed\")\n",
    "df_csv.write.mode(\"overwrite\").json(\"dbfs:/FileStore/json_table\")\n",
    "print(\"Writing to the json file completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "54e4febe-fbb0-4fe5-a368-f0774779190c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Task: 6. Analyzing and Visualizing Streaming Data with Databricks\n",
    "streaming_data = spark.readStream.csv(\"dbfs:/FileStore/real_time_streaming_data.csv\", schema=schema)\n",
    "aggregated_stream = streaming_data.groupBy(\"event_time\").sum(\"amount\")\n",
    "display(aggregated_stream)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e7a7600a-5a1d-467a-b93c-8ba921f68d66",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#  Task:7. Introduction to Databricks Delta Lake (create and update delta table)\n",
    "df.write.mode(\"overwrite\").format(\"delta\").save(\"/delta/transactions\")\n",
    "spark.sql(\"UPDATE delta.`/delta/transactions` SET amount = amount * 1.1 WHERE customer_id = 9363\")\n",
    "previous_version = spark.read.format(\"delta\").option(\"versionAsOf\", 1).load(\"/delta/transactions\")\n",
    "previous_version.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1eb85a0c-a5bf-48d7-a19d-26536d3b918a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Task: 8. Managed and Unmanaged Tables\n",
    "delta_table_path = \"dbfs:/FileStore/delta_table\"\n",
    "df_csv.write.format(\"delta\").mode(\"overwrite\").save(delta_table_path)\n",
    "history_df = spark.sql(\"DESCRIBE HISTORY sales_data\")\n",
    "history_df.show(truncate=False)\n",
    "spark.sql('VACUUM sales_data RETAIN 168 HOURS')\n",
    "historical_version_df = spark.read.format('delta').option('versionAsOf', 1).table('sales_data')\n",
    "historical_version_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4eb3afd7-b222-4b3b-a4ec-3cf6d96c462a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Task:9 Managed and Unmanaged Tables\n",
    "df.write.saveAsTable(\"managed_table\")\n",
    "df.write.option(\"dbfs:/FileStore/exe_sales_data\", \"/mnt/sales_data\").saveAsTable(\"unmanaged_sales\")\n",
    "spark.sql(\"SELECT * FROM managed_table\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e9012410-3b21-4dba-ae72-36befd4425cc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Task:10 Create Views and Temporary Views\n",
    "df.createOrReplaceTempView(\"temp_view\")\n",
    "df.createOrReplaceGlobalTempView(\"global_temp_view\")\n",
    "spark.sql(\"SELECT * FROM temp_view\").show()\n",
    "spark.sql(\"SELECT * FROM global_temp.global_temp_view\").show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Databricks exercises",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
